---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

###
### This file contains commonly used overrides for convenience. Please inspect
### the defaults for each role to find additional override options.
###

## Debug and Verbose options.
debug: false

## Misc
lxc_net_mtu: 1450
bootstrap_host_aio_config: no

lxc_cache_prep_timeout: 3600
lxc_cache_prep_pre_commands: "rm -f /etc/resolv.conf || true"
lxc_cache_prep_post_commands: "ln -s ../run/resolvconf/resolv.conf /etc/resolv.conf -f"
#  Above Added to fix an LXC bug, this should be fixed in releases > 17.0.3

## Security
# keystone_service_adminuri_insecure: true
# keystone_service_internaluri_insecure: true
# keystone_service_publicuri_insecure: true
apply_security_hardening: false

# ## Common Glance Overrides
# ## https://docs.openstack.org/openstack-ansible-os_swift/pike/configure-swift-glance.html
# glance_default_store: swift
# glance_swift_store_auth_version: 3
# glance_swift_store_auth_address: http://"{{ lb1_mgmt_ip }}":5000/v3
# glance_swift_store_container: glance_images
# glance_swift_store_endpoint_type: internalURL
# glance_swift_store_key: '{{ user_variables.stdout }}'
# glance_swift_store_region: RegionOne
# glance_swift_store_user: 'service:glance'

## Glance Options
# Set glance_default_store to "swift" if using Cloud Files or swift backend
# or "rbd" if using ceph backend; the latter will trigger ceph to get
# installed on glance
# glance_default_store: file
glance_notification_driver: noop


## Nova Options
nova_virt_type: qemu
nova_cpu_allocation_ratio: 4.0 
nova_ram_allocation_ratio: 1.0
# As this is a virtual env, don't lose precious memory to the VM itself!
nova_reserved_host_memory_mb: 1024

# ## Cinder Options
# cinder_iscsi_helper: tgtadm
# cinder_iscsi_iotype: fileio
# cinder_iscsi_num_targets: 100
# cinder_iscsi_port: 3260


## Ceph cluster fsid (must be generated before first run)
## Generate a uuid using: python -c 'import uuid; print(str(uuid.uuid4()))'
generate_fsid: true
# fsid: 5b8ced1c-7518-4d83-97a5-64f4b2c01340 # Replace with your generated UUID

## ceph-ansible settings
## See https://github.com/ceph/ceph-ansible/tree/master/group_vars for
## additional configuration options availble.
monitor_address_block: "172.29.236.0/22"
public_network: "172.29.236.0/22"
cluster_network: "172.29.244.0/22"
osd_scenario: collocated
journal_size: 10240 # size in MB
# ceph-ansible automatically creates pools & keys for OpenStack services
openstack_config: true
cinder_ceph_client: cinder
glance_ceph_client: glance
glance_default_store: rbd
glance_rbd_store_pool: images
nova_libvirt_images_rbd_pool: vms
osd_auto_discovery: false # this should detect empty disks and use them as OSDs
# osd_objectstore: bluestore # testing this setting - did not work on pike
osd_objectstore: filestore

cinder_backends:
  RBD:
    volume_driver: cinder.volume.drivers.rbd.RBDDriver
    rbd_pool: volumes
    rbd_ceph_conf: /etc/ceph/ceph.conf
    rbd_store_chunk_size: 8
    volume_backend_name: rbddriver
    rbd_user: "{{ '{{' }} cinder_ceph_client {{ '}}' }}"
    rbd_secret_uuid: "{{ '{{' }} cinder_ceph_client_uuid {{ '}}' }}"
    report_discard_supported: true


## Neutron Options
neutron_l2_population: true
neutron_plugin_base:
  - router
  - neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2
neutron_l3_ha: false


### Following section copied from https://github.com/openstack/openstack-ansible/blob/master/etc/openstack_deploy/user_variables.yml
## Environment variable setup:
## This is used by apt-cacher-ng to download apt packages:
## proxy_env_url: http://{{ hostvars['gw']['ansible_eth1']['ipv4']['address'] }}:8080/
proxy_env_url: http://{{ gw_mgmt_ip }}:8080/

{% raw %}
## This sets up a permanent environment, used during and after deployment:
no_proxy_env: "localhost,127.0.0.1,{{ internal_lb_vip_address }},{{ external_lb_vip_address }},{% for host in groups['all_containers'] %}{{ hostvars[host]['container_address'] }}{% if not loop.last %},{% endif %}{% endfor %}"
global_environment_variables:
  HTTP_PROXY: "{{ proxy_env_url }}"
  HTTPS_PROXY: "{{ proxy_env_url }}"
  NO_PROXY: "{{ no_proxy_env }}"
  http_proxy: "{{ proxy_env_url }}"
  https_proxy: "{{ proxy_env_url }}"
  no_proxy: "{{ no_proxy_env }}"

## This is applied only during deployment, nothing is left after deployment is complete:
# deployment_environment_variables:
#   http_proxy: "{{ proxy_env_url }}"
#   https_proxy: "{{ proxy_env_url }}"
#   no_proxy: "localhost,127.0.0.1,{{ internal_lb_vip_address }},{{ external_lb_vip_address }},{% for host in groups['keystone_all'] %}{{ hostvars[host]['container_address'] }}{% if not loop.last %},{% endif %}{% endfor %}"
{% endraw %}




## HAProxy Options
haproxy_use_keepalived: false
# haproxy_ssl: false

